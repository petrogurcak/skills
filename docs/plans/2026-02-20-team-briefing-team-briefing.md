# Team Briefing: AI Team Briefing Design
> Generated after brainstorming on 2026-02-20
> Personas activated: product, ux

## Product
**Relevance:** 8/10
- [ ] Define success metric: time to write implementation plan after briefing vs before (target: 30% faster) + rework rate per feature
- [ ] Start with fewer personas in practice — Product persona alone catches 80% of real mistakes. Add others when you have bandwidth to act on their feedback
- [ ] Each persona's checklist should include trade-offs: "Feature X takes 3 evenings. Cut Y to fit." — forces prioritization, not scope expansion
- [ ] Phase 2 wrapup should answer: "Which recommendations actually mattered?" — log to DECISIONS.md, weight personas by signal over time
- [ ] Test on ONE real feature first, measure: (1) fewer blockers during build, (2) fewer post-launch surprises, (3) total friction time

## UX
**Relevance:** 9/10
- [ ] Orchestrator should show which personas it's running and which it's skipping — prevents frustration from unexpected wait or missing input
- [ ] Low-relevance personas (< 3/10) should write "No actions required" instead of silence — confirms they reviewed, not that they were skipped
- [ ] Add 1-line summary per persona before detailed checkboxes — enables 10-second scan without reading all suggestions
- [ ] Limit to max 5 personas per run to avoid cognitive overload (35 suggestions = wall of text)
- [ ] Add "Top 3 actions" exit checkpoint — forces prioritization, prevents analysis paralysis

---

## Top 3 Recommendations
> Cross-persona priorities — most impactful actions across all domains

1. **Test on one real feature first and measure impact** (Product) — before scaling, prove it actually speeds up decision-making rather than adding process overhead
2. **Add 1-line summary per persona + Top 3 exit checkpoint** (UX) — prevents the briefing from becoming a wall of unread suggestions
3. **Include trade-offs in suggestions, not just additions** (Product) — each suggestion should say what it costs, not just what it adds
